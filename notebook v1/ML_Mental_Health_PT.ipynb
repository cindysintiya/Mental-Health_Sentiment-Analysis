{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q2lrh_XVJyD"
      },
      "source": [
        "# **Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R4Vw3J2WN8Db"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYOTjM-yOKYf",
        "outputId": "9661417e-420a-44af-bc83-937f956f0fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/suchintikasarkar/sentiment-analysis-for-mental-health\n",
            "License(s): DbCL-1.0\n",
            "Downloading sentiment-analysis-for-mental-health.zip to /content\n",
            " 90% 10.0M/11.1M [00:01<00:00, 13.7MB/s]\n",
            "100% 11.1M/11.1M [00:01<00:00, 8.87MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d \"suchintikasarkar/sentiment-analysis-for-mental-health\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PL0XwQz4OPtC"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "dataset_zip = zipfile.ZipFile(\"/content/sentiment-analysis-for-mental-health.zip\", \"r\")\n",
        "dataset_zip.extractall()\n",
        "dataset_zip.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8NC_C_lVUC2"
      },
      "source": [
        "# **Read and Define Data to Variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ozaZEAjORMC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# raw_data = pd.read_csv(\"/content/Combined Data.csv\")\n",
        "raw_data = pd.read_csv(\"../data/sentiments.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "9RwGQim6OS6K",
        "outputId": "004a2428-15df-4931-bcd9-a8b2291d11cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total data (rows): 52681 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8649</th>\n",
              "      <td>8649</td>\n",
              "      <td>It pains me that this has happened to me. Gran...</td>\n",
              "      <td>Depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18380</th>\n",
              "      <td>18380</td>\n",
              "      <td>every night i son and cry and promise myself t...</td>\n",
              "      <td>Depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48195</th>\n",
              "      <td>48195</td>\n",
              "      <td>Sometimes I find comfort in my depression It h...</td>\n",
              "      <td>Depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7701</th>\n",
              "      <td>7701</td>\n",
              "      <td>I do not have any motivation to be alive anymo...</td>\n",
              "      <td>Depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14741</th>\n",
              "      <td>14741</td>\n",
              "      <td>Who knows who was the first person who thought...</td>\n",
              "      <td>Depression</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                          statement  \\\n",
              "8649         8649  It pains me that this has happened to me. Gran...   \n",
              "18380       18380  every night i son and cry and promise myself t...   \n",
              "48195       48195  Sometimes I find comfort in my depression It h...   \n",
              "7701         7701  I do not have any motivation to be alive anymo...   \n",
              "14741       14741  Who knows who was the first person who thought...   \n",
              "\n",
              "           status  \n",
              "8649   Depression  \n",
              "18380  Depression  \n",
              "48195  Depression  \n",
              "7701   Depression  \n",
              "14741  Depression  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = raw_data.dropna()\n",
        "print(\"Total data (rows):\", len(df), \"\\n\")\n",
        "\n",
        "df.sample(frac = 1).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq3DdyCVkRe"
      },
      "source": [
        "# **Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfpOrNo0OVuJ",
        "outputId": "1fa2ae1d-1a5d-4e11-8c33-8ec852e54204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total classes/ labels: 7 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar',\n",
              "       'Personality disorder'], dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = df['status'].unique()\n",
        "print(\"Total classes/ labels:\", len(classes), \"\\n\")\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "8SqxOCZ7Om2l",
        "outputId": "acf050c6-706a-4624-8062-1e723e3a2c83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anxiety</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Depression</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suicidal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stress</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bipolar</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Personality disorder</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Class Name  Value\n",
              "0               Anxiety      0\n",
              "1                Normal      1\n",
              "2            Depression      2\n",
              "3              Suicidal      3\n",
              "4                Stress      4\n",
              "5               Bipolar      5\n",
              "6  Personality disorder      6"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def to_class_num(class_name):\n",
        "    class_list_num = np.where(classes == class_name)[0][0]\n",
        "    return class_list_num\n",
        "\n",
        "def to_class_name(class_num):\n",
        "    return classes[class_num]\n",
        "\n",
        "classes_pd = pd.DataFrame({\n",
        "    \"Class Name\" : classes,\n",
        "    \"Value\" : [to_class_num(class_name) for class_name in classes]\n",
        "})\n",
        "display(classes_pd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-1A7txdXR0u"
      },
      "source": [
        "# **Train-Test Split & Preprocessing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr8Ab1G5OXkC",
        "outputId": "a7828841-f36d-47bc-ec98-ad482c50621e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39510 39510 13171 13171\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_data = df['statement']\n",
        "y_data = df['status']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data.values, y_data.values)\n",
        "print(len(x_train), len(y_train), len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P7qRKd4yObRR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='UNK', lower = True)\n",
        "tokenizer.fit_on_texts(x_data.values)\n",
        "\n",
        "x_train_tokenized = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_tokenized = tokenizer.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htMAE9yROeLh",
        "outputId": "7dffc493-75e7-4500-a02b-3c8add47c60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6300\n"
          ]
        }
      ],
      "source": [
        "max_len = max([len(x) for x in x_train_tokenized])\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgCZ0qdMOhJx",
        "outputId": "5342da5a-ffcf-4102-964b-5d9f90875795"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0,   0,   0, ...,  43,   5, 120])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train_tokenized_padded = pad_sequences(x_train_tokenized, maxlen = max_len)\n",
        "x_test_tokenized_padded = pad_sequences(x_test_tokenized, maxlen = max_len)\n",
        "\n",
        "x_train_tokenized_padded[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DfFM1tSSNHo",
        "outputId": "968385b4-f629-4271-8500-3b7679e2c53a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "63341"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iUwJ58iXYth"
      },
      "source": [
        "# **Defining Device and Transforming Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUAf87emSO0x",
        "outputId": "789ad4ad-7df9-4da6-a604-93e95d3e6f57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Device:\", device, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qwUcCTiizqu",
        "outputId": "d8565c2f-abe1-43e5-8709-7be4f9a8ac5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([  0,   0,   0,  ...,  43,   5, 120], dtype=torch.int32), tensor(1))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomizedDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.x[idx])\n",
        "        y = torch.tensor(to_class_num(self.y[idx]))\n",
        "        return x, y\n",
        "\n",
        "sample = CustomizedDataset(x_train_tokenized_padded, y_train)\n",
        "sample[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKefvvCfXvOn"
      },
      "source": [
        "# **Batch Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SInf-NNwSorx",
        "outputId": "5a0ed5ec-2f92-4356-e764-550224aae724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x22df6ea3a60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 24\n",
        "train_dataloader = DataLoader(CustomizedDataset(x_train_tokenized_padded, y_train), shuffle = True, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(CustomizedDataset(x_test_tokenized_padded, y_test), shuffle = True, batch_size = batch_size)\n",
        "\n",
        "train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc4J61pvYFRs"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fLewwGJMbq6",
        "outputId": "4448fab5-81d9-4401-ed7e-f2f166d45ee0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SentimentAnalysisModel(\n",
              "  (embd): Embedding(63341, 64, padding_idx=0)\n",
              "  (lstm): LSTM(64, 64, bidirectional=True)\n",
              "  (linear): Linear(in_features=806400, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "num_lstm = 1\n",
        "num_hidden = 64\n",
        "embedding_size = 64\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "class SentimentAnalysisModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embd = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_size, num_hidden, bidirectional = True, num_layers=num_lstm)\n",
        "        self.linear = nn.Linear(2 * num_hidden * max_len, len(classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.embd(x)\n",
        "        logits , (h_n, c_n) = self.lstm(logits)\n",
        "        logits = logits.flatten(start_dim = 1, end_dim=-1)\n",
        "        logits = self.linear(logits)\n",
        "        probability = softmax(logits)\n",
        "        return logits, probability\n",
        "\n",
        "model = SentimentAnalysisModel()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wbfzhzpO_od",
        "outputId": "74b32964-9588-4fb1-80da-8c0d470390bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6300])\n",
            "torch.Size([1, 7])\n"
          ]
        }
      ],
      "source": [
        "test = x_train_tokenized_padded[0]\n",
        "test = torch.from_numpy(test[None, :])\n",
        "print(test.shape)\n",
        "pred, prob = model(test)\n",
        "print(pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "8HnUYgeRUgLu",
        "outputId": "faf5eac4-1b4f-4a55-a635-422d084b306b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 262/1647 [05:17<27:59,  1.21s/it]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy(pred, y)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "epochs = 3   # 32\n",
        "\n",
        "avg_loss = []\n",
        "avg_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    acc = 0\n",
        "    loss_acc = 0\n",
        "    n = 0\n",
        "\n",
        "    for x, y in tqdm(train_dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        pred, prob = model(x)\n",
        "\n",
        "        loss = cross_entropy(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        output = pred.argmax(axis=1)\n",
        "\n",
        "        acc += (output == y).sum().item()\n",
        "        n += y.shape[0]\n",
        "        loss_acc += loss.item()\n",
        "\n",
        "    avg_loss.append(loss_acc / len(train_dataloader))\n",
        "    avg_acc.append(acc / n)\n",
        "    print('avg loss:', loss_acc / len(train_dataloader))\n",
        "    print('avg acc :', acc / n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSn1dZjXPy5N",
        "outputId": "5df459fb-3dcc-4b13-8b7a-ae2285aa12bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 549/549 [00:09<00:00, 58.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg test acc: 0.701009794244932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "n = 0\n",
        "acc = 0\n",
        "for x, y in tqdm(test_dataloader):\n",
        "    pred, prob = model(x.to(device))\n",
        "    output = pred.argmax(axis = 1)\n",
        "    n += y.shape[0]\n",
        "    acc += (output == y.to(device)).sum().item()\n",
        "print('avg test acc:', acc / n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "gLEF61HSbsrf"
      },
      "outputs": [],
      "source": [
        "# Save entire model\n",
        "\n",
        "PATH = '/content/my_model_4.h5'\n",
        "torch.save(model, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Predicting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_hUf4VeQjz0",
        "outputId": "95496108-800d-47d0-cd3d-c8d470c674b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What's your matter?\n",
            "im hopeless, need someone here before i kill myself\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('Suicidal', 0.8255137205123901)"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict_sentiment(text):\n",
        "    input_tensor = torch.from_numpy(pad_sequences(tokenizer.texts_to_sequences([text]), maxlen = max_len))\n",
        "    pred, prob = model(input_tensor.to(device))\n",
        "    pred = pred.cpu().detach().numpy().argmax(axis=1).flatten()[0]\n",
        "    return to_class_name(pred), prob.max().item()\n",
        "\n",
        "predict_sentiment(input(\"What's your matter?\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "iDnEw0g4Q3pe"
      },
      "outputs": [],
      "source": [
        "# im hopeless, need someone here before i kill myself\n",
        "# I feel very stressed from a few days everyone hates me I have not been happy from over a month\n",
        "# this is the happiest day of my life, my life is going to be perfect  // 1 by 1: normal, both: suicide??"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
